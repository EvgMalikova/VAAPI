<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.16"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>VAAPI: Visual-auditory API</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">VAAPI
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.16 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">Visual-auditory API </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h1><a class="anchor" id="autotoc_md16"></a>
Introduction</h1>
<p>Scalar fields are used in many research areas, where computer simulations or experimental studies are involved, such as computational chemistry, medical data analysis and physical phenomena studies. Visualisation of scalar fields usually employs Volume Rendering techniques as for the computer systems the scalar fields data is often converted to data volumes stored in the texture memory. The visual analysis of scalar fields is not always straightforward, especially when a complex dynamic phenomenon is represented. In Volume Rendering the Multidimensional Transfer functions (TF) and consideration of more complex object-light interaction processes in the optical model is used to address the issues of visual analysis quality improvement and highlight features of interest. <br  />
</p>
<p>However, the visual perception limitations not always can be overcome solely with the enhancement of the optical model. The visual system can be overloaded and perturbed due to fatigue. An additional introduction of auditory sensory stimuli to address a problem of visual analysis limitations is a well-known technique, called <a href="https://sonification.de/handbook/">sonification</a>. <br  />
</p>
<p>This API targets the problems of the visual-auditory interactive study of the dynamic scalar fields using the concept of a heterogeneous object influencing various sensory stimuli. The API takes advantages of the similarities between light and sound propagation to suggest a novel procedure of a visual-auditory rendering based on the ray-casting procedure. It makes it possible to conduct a simultaneous visual analysis along with spatial positioning/measuring. The API suggests rendering and modelling of both surface and solid geometry with visual and auditory properties. However mainly it is concentrated on the Volume scene representation based on the HyperVolume (HV) model and take advantage of the Signed Distance Fields (SDF) for rendering. <br  />
 The concept introduces three separate parts of the HV model for Volume Rendering that can be evaluated independently on demand to speed up the rendering process of complex dynamic volume objects and a general visual-auditory scene representation for interactive Volume Rendering.</p>
<p>For more details, on heterogeneous objects modelling and HyperVolume approach look at <a class="el" href="md_doc_approach.html">Approach Overview</a> Section:</p>
<h1><a class="anchor" id="autotoc_md17"></a>
Optix engine and VTK</h1>
<p>The API is based on Optix Engine and takes advantage of it's native rendering acceleration structures like BVH. The API syntacsis is mainly a "copy" of <a href="http://vtk.org">Visualization Toolkit</a>. As well it much inherits the standard visualisation concepts reflected in VTK API, like visualisation pipeline, replacing it with notion of visual-auditory pipeline, unified on base of ray-casting procedure. Thus, API targets to provide high level access to geometric modelling and rendering, allowing the researcher or programmer to operate familiar visualisation concepts and terminology. At the same time it is very lightweight and fast as all core procedures are CUDA kernals running on NVIDIA GPU card. The API it mostly oriented to support geometry modelling on base of <a href="http://hyperfun.org">FRep concept</a> and targets various aspects of multisensory interaction, like collision detection, interactive manipulations and etc.</p>
<p>For concept of basic use, similarities and differencec to VTK see <a class="el" href="md_doc_vtkstyle.html">API basics</a> For FRep modelling example look <a class="el" href="md_doc_freptutorial.html">FRep tutorial</a></p>
<h1><a class="anchor" id="autotoc_md18"></a>
Examples</h1>
<p>There are several basic tutorials for users and developers in <a class="el" href="md_doc_alltutorials.html">Tutorials </a></p>
<p>Some featured examples:</p><ul>
<li>For examples of Visual-auditory volume and SDF geometry ray-casting see <a class="el" href="md_doc_examples.html">Examples</a></li>
</ul>
<h1><a class="anchor" id="autotoc_md19"></a>
Naming structure</h1>
<p>Most of API classes have preffix "va" (for example <a class="el" href="classva_basic_renderer.html" title="Abstract visual-auditory renderer.">vaBasicRenderer</a>). The data Readers names are formed with prefix of file format. For example xyzReader. All primitives and operations of FRep geometric modelling and Readers that return SDF representation, in other words can be directly used within FRep modelling pipeline without any mapping, have "sdf" prefix. For example sdfSphere, sdfBox, sdfTextureReader and etc.</p>
<h1><a class="anchor" id="autotoc_md20"></a>
Presequencies</h1>
<p>The API is based on <a href="https://developer.nvidia.com/optix">Optix engine</a>. The visual and auditory rendering is performed through use of <a href="https://www.opengl.org/">OpenGl</a> and <a href="https://www.openal.org/downloads/">OpenAL</a> accordingly. For details on visual-auditory rendering interopability see implementation of <a class="el" href="classoptical_model.html" title="Actual binding through texture of the cuda output.">opticalModel</a> class: for optical model and <a class="el" href="classauditory_model.html" title="The class responsible for rendering auditory propertis.">auditoryModel</a> class: for 3D sound rendering. Additionally, some of the API classes use the following open source libraries (those procedures might be not used and libraries excluded from the project):</p>
<ul>
<li>Readers: <a href="http://itk.org">ITK</a> for data preprocessing</li>
<li><a class="el" href="namespacestk_sound.html">stkSound</a> class: :<a href="https://ccrma.stanford.edu/software/stk/">STK</a> for sound synthesis</li>
</ul>
<h1><a class="anchor" id="autotoc_md21"></a>
TODO</h1>
<ul>
<li>Haptic implementation<ul>
<li>Collision detection</li>
</ul>
</li>
<li>Practical examples<ul>
<li>Molecular haptics -Visual-auditory tutorials -Extending API (advanced tutorials) </li>
</ul>
</li>
</ul>
</div></div><!-- PageDoc -->
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.16
</small></address>
</body>
</html>
